{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "2v4IZbJfyxr2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AffwCk3BVMt8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "outputId": "5a67b022-dd0a-47ad-c88a-20cb53769a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting cryptography>=36.0.0\n",
            "  Downloading cryptography-38.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 40.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from pdfminer.six) (2.1.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
            "Installing collected packages: cryptography, pdfminer.six\n",
            "Successfully installed cryptography-38.0.4 pdfminer.six-20221105\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-2.12.1-py3-none-any.whl (222 kB)\n",
            "\u001b[K     |████████████████████████████████| 222 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from PyPDF2) (4.4.0)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-2.12.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.7.6-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pdfminer.six==20221105 in /usr/local/lib/python3.8/dist-packages (from pdfplumber) (20221105)\n",
            "Collecting Pillow>=9.1\n",
            "  Downloading Pillow-9.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 9.1 MB/s \n",
            "\u001b[?25hCollecting Wand>=0.6.10\n",
            "  Downloading Wand-0.6.10-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 67.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from pdfminer.six==20221105->pdfplumber) (2.1.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.8/dist-packages (from pdfminer.six==20221105->pdfplumber) (38.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n",
            "Installing collected packages: Wand, Pillow, pdfplumber\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "Successfully installed Pillow-9.3.0 Wand-0.6.10 pdfplumber-0.7.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ZEYA AHMAD(929)8440942  | za2291@columbia.edu | https://www.linkedin.com/in/zeyaahmad/ | https://github.com/zeya30EDUCATIONCOLUMBIA UNIVERSITY Sep 2021-Dec 2022(Expected)M.A. in Statistics (Machine Learning track)Relevant Courses:Applied Linear Regression Models, Statistical Machine Learning, Databases, TensorFlow in Python, EDABIRLA INSTITUTE OF TECHNOLOGY AND SCIENCE(BITS),PILANI Sep 2015-June 2019B.E.(Hons.) in Computer ScienceRelevant Courses:Data Mining,Information Retrieval,Artificial Intelligence,Data Structures & Algorithms,OptimizationTECHNICAL SKILLSProgramming Languages: Python , R ,Java, SQL, SAS,C++ , HTML5/CSS, Microsoft ExcelLibraries/Framework:TensorFlow,Keras,PyTorch,Scikit-Learn,Pandas,NumPy,SciPy,Matplotlib,Seaborn,BeautifulSoup,Selenium,NLTK,RASA, Flask,tidyr,dplyr,ggplot2,R shiny,StreamlitSpecialization:Machine Learning(GLM,Linear Regression,LogisticRegression,KNN,Random Forest,Clustering,Decision Trees ,SVM,Classification),Data Analysis(A/B Testing,Data Modeling),Business Intelligence(Tableau,ProductAnalysis),Feature Engineering,Statistical  Modeling, Web Scraping, NLP, Predictive Modeling, Time Series Analysis, Hypothesis Testing, Reinforcement LearningDatabase/ETL: MySQL,MongoDB,Amazon DynamoDBOther Tools:Tableau,Spark,Hadoop,Git,AWS(Glue ETL,Athena,EC2,Lambda,RDS,SageMaker,S3),PowerBI,Google Cloud PlatformPROFESSIONAL EXPERIENCENEXTGEN HQ New York City, USAData Science & Strategy Consultant May 2022 - Aug2022 Built SQL scripts to generate weekly KPI reports, which decreased 30% of the data generating time Evaluated 3 A/B tests using Python & SQL to make informed recommendations on product changes. Used Python to build a decision tree with an accuracy of 86%, resulting in a 3% increase in VIP conversion Designed and conducted experiments on incentive programs, which increased VIP retention by 10%CUREFY New Delhi, IndiaData Science Intern Sep 2020 - April 2021 Developed a Healthcare Chatbot for online self-diagnosis and directing users to the appropriate medical practitioner based onsymptoms/text input by the user,usingInfermedicaAPI,RASA NLU framework and Python spaCy for NLP.JOHNSON CONTROLS Dubai, UAEBusiness Intelligence Intern Aug 2018- Jan 2019 Used SQL to build 6 dashboards from 1M+ customer data, which caused saving 10 work hours per week Generated 8 Tableau reports to support decision-making in: CRM, sales pipeline, recruiting, invoicing and ticketing.PROJECTSIMDB Movie Recommendation System Project |Kaggle| Python Mar 2021- Jun 2021 Created a hybrid recommendation system(Collaborative Filtering + Content-Based Filtering) basedon10k+usersand45kmoviesacross 30 years, that resulted in a 5% increase in basket size and improved RMSE from 1.34 to 0.86. Constructed collaborativefiltering and matrix factorizations using Alternating Least Squares with a Temporal Dynamics Regularization. Constructed content-based model through TF-IDF word embedding, LDA topic modeling, Pearson Correlation, and SentimentAnalysis (Natural Language Processing). Recommended top N similar movies with positive user comments.Analyzing neighborhoods in Bangalore | Capstone Project| Python Jun 2020 - Sep 2020 Implemented K-means Clustering algorithm to analyze and select the most suitable locations in Bangalore for opening a newshopping mall by Web Scraping Wikipedia page containing list oftheneighborhoodsinBangalore.UsedFoursquareAPItoobtainthe venue data for the neighborhoods and Geocoder library to obtain  geographical coordinates of the neighborhoods.Amazon Fake Review Detection | Kaggle | Python Sep 2019 - Dec 2019 Used text-mining and classification model to analyze 4+ million customer reviews of mobile phones sold on Amazon to predictitem ratings and prevent fake reviews with over 85% recall score. Cleaned unstructured text data by handling missing values and categoricaldata,processedsegmentation,andvectorizeddatafromtext into numeric using TF-IDF.Constructed data pipelines to train models including Decision Tree, Naive Bayes, and LogisticRegression to predict rating based on reviews with over 85% accuracy and evaluated models by AUROC and F1 score.Predicting Success of Spotify Songs |  BITS Pilani | Python Mar 2019 - May 2019 Used a dataset of 228,000 Spotify Tracks to predict popularity of a track(greater than 57 popularity) using audio-based metricssuch as key, mode, anddanceabilitywithoutexternalmetricssuchasartistname,genre,andreleasedate.RandomForestClassifierwas the best performing algorithm (92 % accuracy and 86.4% AUC).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!pip3 install pdfminer.six \n",
        "!pip install PyPDF2\n",
        "!pip install pdfplumber\n",
        "import pdfminer.high_level\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "import PyPDF2,pdfplumber \n",
        " \n",
        "\n",
        "CV_File=open('/content/ZeyaAhmadResume.pdf','rb')\n",
        "Script=PyPDF2.PdfFileReader(CV_File)\n",
        "pages=Script.numPages\n",
        "\n",
        "Script = []\n",
        "with pdfplumber.open(CV_File) as pdf:\n",
        "    for i in range (0,pages):\n",
        "        page=pdf.pages[i]\n",
        "        text=page.extract_text()\n",
        "        # print (text)\n",
        "        Script.append(text)\n",
        "        \n",
        "Script=''.join(Script)\n",
        "CV_Clear = Script.replace(\"\\n\",\"\").replace('●', \"\")\n",
        "CV_Clear    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "iS4ZLt0f8hc5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# search inputs: \n",
        "title = input('Enter your desired position: ').strip()\n",
        "location = input('Enter your desired location: ').strip()\n",
        "no_pages = int(input('Enter the # of pages to scrape: '))\n",
        "\n",
        "\n",
        "info = []\n",
        "headers = {'User-agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36'}\n",
        "\n",
        "for page in range(no_pages):\n",
        "    getVars = {'keywords' : title, 'location' : location ,'sort' : 'date', 'start': str(no_pages*10)}\n",
        "    url = ('https://www.linkedin.com/jobs/search?' + urllib.parse.urlencode(getVars))\n",
        "    print(url)\n",
        "    r = requests.get(url, headers=headers)\n",
        "    html = r.content\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    \n",
        "    jobs = soup.find_all('div', class_ = 'base-card relative w-full hover:no-underline focus:no-underline base-card--link base-search-card base-search-card--link job-search-card')\n",
        "    \n",
        "    for job in jobs:\n",
        "        title = str(job.find('h3', class_='base-search-card__title').text.strip())\n",
        "        company = str(job.find('h4', class_='base-search-card__subtitle').text.strip())\n",
        "        post_date = datetime.strptime(job.find('time')['datetime'], '%Y-%m-%d').date()\n",
        "        link = job.find('a', class_='base-card__full-link')['href']\n",
        "        \n",
        "        info.append([title,company,post_date,link])\n",
        "    \n",
        "\n",
        "info_dict_list = defaultdict(list)\n",
        "\n",
        "cols = ['Job_title','Company','Job_posted_date','Link']\n",
        "info_table = pd.DataFrame(info, columns = cols)\n",
        "# sort by post date\n",
        "info_table = info_table.sort_values(by = 'Job_posted_date', ascending = False).reset_index(drop=True)\n",
        "info_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZbNqLBWlM50b",
        "outputId": "817d7163-ab2a-4042-806e-26e6282d962a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your desired position: Data Scientist\n",
            "Enter your desired location: New York\n",
            "Enter the # of pages to scrape: 1\n",
            "https://www.linkedin.com/jobs/search?keywords=Data+Scientist&location=New+York&sort=date&start=10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Job_title  \\\n",
              "0                 Data Scientist, Product Analytics   \n",
              "1                                    Data Scientist   \n",
              "2                                    Data Scientist   \n",
              "3                                    Data Scientist   \n",
              "4                           Data Scientist, Product   \n",
              "5              Data Scientist - Marketing Analytics   \n",
              "6                                    Data Scientist   \n",
              "7           Data Scientist (Deep Learning), Peacock   \n",
              "8                          Data Scientist Full Time   \n",
              "9                                    Data Scientist   \n",
              "10                                   Data Scientist   \n",
              "11                                   Data Scientist   \n",
              "12                             Data Scientist [NYC]   \n",
              "13                                   Data Scientist   \n",
              "14         Data Scientist - Global Decision Science   \n",
              "15                                   Data Scientist   \n",
              "16                                   Data Scientist   \n",
              "17                                   Data Scientist   \n",
              "18                                   Data Scientist   \n",
              "19                        Machine Learning Engineer   \n",
              "20  Data Strategy, Data Scientist – Equity Research   \n",
              "21            Machine Learning Engineer - US Remote   \n",
              "22                                   Data Scientist   \n",
              "23                                   Data Scientist   \n",
              "24                  Machine Learning Engineer (NLP)   \n",
              "\n",
              "                           Company Job_posted_date  \\\n",
              "0              Peloton Interactive      2022-12-14   \n",
              "1               Top Prospect Group      2022-12-13   \n",
              "2                           TikTok      2022-12-12   \n",
              "3                          Epsilon      2022-12-10   \n",
              "4                            Asana      2022-12-08   \n",
              "5                          Spotify      2022-12-08   \n",
              "6                 lululemon Studio      2022-12-06   \n",
              "7                          Peacock      2022-12-06   \n",
              "8                Bardess Group Ltd      2022-12-06   \n",
              "9                           Amicus      2022-12-06   \n",
              "10                          TikTok      2022-12-03   \n",
              "11              The New York Times      2022-12-03   \n",
              "12                     CarbonChain      2022-12-02   \n",
              "13                       Grammarly      2022-12-02   \n",
              "14                American Express      2022-12-01   \n",
              "15                        McKinney      2022-11-26   \n",
              "16                    Revelio Labs      2022-11-26   \n",
              "17  Carrie Rikon & Associates, LLC      2022-11-26   \n",
              "18  Carrie Rikon & Associates, LLC      2022-11-26   \n",
              "19                         Verneek      2022-11-23   \n",
              "20                       Jefferies      2022-11-22   \n",
              "21                    Hugging Face      2022-11-13   \n",
              "22                      Afficiency      2022-11-09   \n",
              "23   Atlantic Partners Corporation      2022-10-23   \n",
              "24                    BLACKBIRD.AI      2022-09-11   \n",
              "\n",
              "                                                 Link  \n",
              "0   https://www.linkedin.com/jobs/view/data-scient...  \n",
              "1   https://www.linkedin.com/jobs/view/data-scient...  \n",
              "2   https://www.linkedin.com/jobs/view/data-scient...  \n",
              "3   https://www.linkedin.com/jobs/view/data-scient...  \n",
              "4   https://www.linkedin.com/jobs/view/data-scient...  \n",
              "5   https://www.linkedin.com/jobs/view/data-scient...  \n",
              "6   https://www.linkedin.com/jobs/view/data-scient...  \n",
              "7   https://www.linkedin.com/jobs/view/data-scient...  \n",
              "8   https://www.linkedin.com/jobs/view/data-scient...  \n",
              "9   https://www.linkedin.com/jobs/view/data-scient...  \n",
              "10  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "11  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "12  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "13  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "14  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "15  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "16  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "17  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "18  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "19  https://www.linkedin.com/jobs/view/machine-lea...  \n",
              "20  https://www.linkedin.com/jobs/view/data-strate...  \n",
              "21  https://www.linkedin.com/jobs/view/machine-lea...  \n",
              "22  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "23  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "24  https://www.linkedin.com/jobs/view/machine-lea...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40a27cd8-669e-4934-a191-1e1576f61e56\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job_title</th>\n",
              "      <th>Company</th>\n",
              "      <th>Job_posted_date</th>\n",
              "      <th>Link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Scientist, Product Analytics</td>\n",
              "      <td>Peloton Interactive</td>\n",
              "      <td>2022-12-14</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Top Prospect Group</td>\n",
              "      <td>2022-12-13</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>TikTok</td>\n",
              "      <td>2022-12-12</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Epsilon</td>\n",
              "      <td>2022-12-10</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Scientist, Product</td>\n",
              "      <td>Asana</td>\n",
              "      <td>2022-12-08</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Data Scientist - Marketing Analytics</td>\n",
              "      <td>Spotify</td>\n",
              "      <td>2022-12-08</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>lululemon Studio</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Data Scientist (Deep Learning), Peacock</td>\n",
              "      <td>Peacock</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Data Scientist Full Time</td>\n",
              "      <td>Bardess Group Ltd</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Amicus</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>TikTok</td>\n",
              "      <td>2022-12-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>2022-12-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Data Scientist [NYC]</td>\n",
              "      <td>CarbonChain</td>\n",
              "      <td>2022-12-02</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Grammarly</td>\n",
              "      <td>2022-12-02</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Data Scientist - Global Decision Science</td>\n",
              "      <td>American Express</td>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>McKinney</td>\n",
              "      <td>2022-11-26</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Revelio Labs</td>\n",
              "      <td>2022-11-26</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Carrie Rikon &amp; Associates, LLC</td>\n",
              "      <td>2022-11-26</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Carrie Rikon &amp; Associates, LLC</td>\n",
              "      <td>2022-11-26</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Machine Learning Engineer</td>\n",
              "      <td>Verneek</td>\n",
              "      <td>2022-11-23</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Data Strategy, Data Scientist – Equity Research</td>\n",
              "      <td>Jefferies</td>\n",
              "      <td>2022-11-22</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-strate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Machine Learning Engineer - US Remote</td>\n",
              "      <td>Hugging Face</td>\n",
              "      <td>2022-11-13</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Afficiency</td>\n",
              "      <td>2022-11-09</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Atlantic Partners Corporation</td>\n",
              "      <td>2022-10-23</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Machine Learning Engineer (NLP)</td>\n",
              "      <td>BLACKBIRD.AI</td>\n",
              "      <td>2022-09-11</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40a27cd8-669e-4934-a191-1e1576f61e56')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40a27cd8-669e-4934-a191-1e1576f61e56 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40a27cd8-669e-4934-a191-1e1576f61e56');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match_percent = []\n",
        "for l in info_table['Link']: \n",
        "    \n",
        "    # extract job description from 2nd webpage (ie, main page for each job post)\n",
        "    r = requests.get(l, headers=headers)\n",
        "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
        "    job_description = soup.find('div', class_='show-more-less-html__markup show-more-less-html__markup--clamp-after-5').text.replace(\"\\n\",\"\")\n",
        "    \n",
        "    # calculate match percentage \n",
        "    Match_Test = [CV_Clear,job_description]\n",
        "    cv = CountVectorizer()\n",
        "    count_matrix = cv.fit_transform(Match_Test)\n",
        "    MatchPercentage = cosine_similarity(count_matrix)[0][1]*100\n",
        "    match_percent.append(MatchPercentage)\n",
        "    \n",
        "match_percent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_frh_jPdfmzp",
        "outputId": "1190b6e6-6d29-491f-bc58-791cc5b05c59"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[61.883468051153834,\n",
              " 55.73384442479171,\n",
              " 60.527459641648676,\n",
              " 61.385708785596115,\n",
              " 58.44522725278725,\n",
              " 55.39328332692528,\n",
              " 55.162251487936246,\n",
              " 62.87477273146077,\n",
              " 56.92702224901009,\n",
              " 47.97039108016488,\n",
              " 60.370927378517905,\n",
              " 59.26137968901206,\n",
              " 58.21452573589434,\n",
              " 55.87402534246038,\n",
              " 62.232565393424366,\n",
              " 46.83845978397522,\n",
              " 51.27348825819878,\n",
              " 58.211078246346226,\n",
              " 58.595425700676294,\n",
              " 47.07516851205012,\n",
              " 59.0126700269341,\n",
              " 47.78527141434946,\n",
              " 62.93423142075299,\n",
              " 58.68186189223499,\n",
              " 60.47971879176812]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match_percent = pd.DataFrame(match_percent, columns = ['Matching_percentage'])\n",
        "final_info_table = pd.concat([info_table, match_percent], axis=1)\n",
        "final_info_table = final_info_table.sort_values(by = 'Matching_percentage', axis = 0, ascending=False)"
      ],
      "metadata": {
        "id": "4Y_EQvJkgZlg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export tp csv file: \n",
        "final_info_table.to_csv('final_info_table1.csv', index=False)\n",
        "final_info_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "roBEOmcRgnAL",
        "outputId": "5dc204bd-96ff-415d-d152-ade93dbb80e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Job_title  \\\n",
              "22                                   Data Scientist   \n",
              "7           Data Scientist (Deep Learning), Peacock   \n",
              "14         Data Scientist - Global Decision Science   \n",
              "0                 Data Scientist, Product Analytics   \n",
              "3                                    Data Scientist   \n",
              "2                                    Data Scientist   \n",
              "24                  Machine Learning Engineer (NLP)   \n",
              "10                                   Data Scientist   \n",
              "11                                   Data Scientist   \n",
              "20  Data Strategy, Data Scientist – Equity Research   \n",
              "23                                   Data Scientist   \n",
              "18                                   Data Scientist   \n",
              "4                           Data Scientist, Product   \n",
              "12                             Data Scientist [NYC]   \n",
              "17                                   Data Scientist   \n",
              "8                          Data Scientist Full Time   \n",
              "13                                   Data Scientist   \n",
              "1                                    Data Scientist   \n",
              "5              Data Scientist - Marketing Analytics   \n",
              "6                                    Data Scientist   \n",
              "16                                   Data Scientist   \n",
              "9                                    Data Scientist   \n",
              "21            Machine Learning Engineer - US Remote   \n",
              "19                        Machine Learning Engineer   \n",
              "15                                   Data Scientist   \n",
              "\n",
              "                           Company Job_posted_date  \\\n",
              "22                      Afficiency      2022-11-09   \n",
              "7                          Peacock      2022-12-06   \n",
              "14                American Express      2022-12-01   \n",
              "0              Peloton Interactive      2022-12-14   \n",
              "3                          Epsilon      2022-12-10   \n",
              "2                           TikTok      2022-12-12   \n",
              "24                    BLACKBIRD.AI      2022-09-11   \n",
              "10                          TikTok      2022-12-03   \n",
              "11              The New York Times      2022-12-03   \n",
              "20                       Jefferies      2022-11-22   \n",
              "23   Atlantic Partners Corporation      2022-10-23   \n",
              "18  Carrie Rikon & Associates, LLC      2022-11-26   \n",
              "4                            Asana      2022-12-08   \n",
              "12                     CarbonChain      2022-12-02   \n",
              "17  Carrie Rikon & Associates, LLC      2022-11-26   \n",
              "8                Bardess Group Ltd      2022-12-06   \n",
              "13                       Grammarly      2022-12-02   \n",
              "1               Top Prospect Group      2022-12-13   \n",
              "5                          Spotify      2022-12-08   \n",
              "6                 lululemon Studio      2022-12-06   \n",
              "16                    Revelio Labs      2022-11-26   \n",
              "9                           Amicus      2022-12-06   \n",
              "21                    Hugging Face      2022-11-13   \n",
              "19                         Verneek      2022-11-23   \n",
              "15                        McKinney      2022-11-26   \n",
              "\n",
              "                                                 Link  Matching_percentage  \n",
              "22  https://www.linkedin.com/jobs/view/data-scient...            62.934231  \n",
              "7   https://www.linkedin.com/jobs/view/data-scient...            62.874773  \n",
              "14  https://www.linkedin.com/jobs/view/data-scient...            62.232565  \n",
              "0   https://www.linkedin.com/jobs/view/data-scient...            61.883468  \n",
              "3   https://www.linkedin.com/jobs/view/data-scient...            61.385709  \n",
              "2   https://www.linkedin.com/jobs/view/data-scient...            60.527460  \n",
              "24  https://www.linkedin.com/jobs/view/machine-lea...            60.479719  \n",
              "10  https://www.linkedin.com/jobs/view/data-scient...            60.370927  \n",
              "11  https://www.linkedin.com/jobs/view/data-scient...            59.261380  \n",
              "20  https://www.linkedin.com/jobs/view/data-strate...            59.012670  \n",
              "23  https://www.linkedin.com/jobs/view/data-scient...            58.681862  \n",
              "18  https://www.linkedin.com/jobs/view/data-scient...            58.595426  \n",
              "4   https://www.linkedin.com/jobs/view/data-scient...            58.445227  \n",
              "12  https://www.linkedin.com/jobs/view/data-scient...            58.214526  \n",
              "17  https://www.linkedin.com/jobs/view/data-scient...            58.211078  \n",
              "8   https://www.linkedin.com/jobs/view/data-scient...            56.927022  \n",
              "13  https://www.linkedin.com/jobs/view/data-scient...            55.874025  \n",
              "1   https://www.linkedin.com/jobs/view/data-scient...            55.733844  \n",
              "5   https://www.linkedin.com/jobs/view/data-scient...            55.393283  \n",
              "6   https://www.linkedin.com/jobs/view/data-scient...            55.162251  \n",
              "16  https://www.linkedin.com/jobs/view/data-scient...            51.273488  \n",
              "9   https://www.linkedin.com/jobs/view/data-scient...            47.970391  \n",
              "21  https://www.linkedin.com/jobs/view/machine-lea...            47.785271  \n",
              "19  https://www.linkedin.com/jobs/view/machine-lea...            47.075169  \n",
              "15  https://www.linkedin.com/jobs/view/data-scient...            46.838460  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4741674-6f54-4f4e-8b63-4e21d3d91c35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job_title</th>\n",
              "      <th>Company</th>\n",
              "      <th>Job_posted_date</th>\n",
              "      <th>Link</th>\n",
              "      <th>Matching_percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Afficiency</td>\n",
              "      <td>2022-11-09</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>62.934231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Data Scientist (Deep Learning), Peacock</td>\n",
              "      <td>Peacock</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>62.874773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Data Scientist - Global Decision Science</td>\n",
              "      <td>American Express</td>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>62.232565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Scientist, Product Analytics</td>\n",
              "      <td>Peloton Interactive</td>\n",
              "      <td>2022-12-14</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>61.883468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Epsilon</td>\n",
              "      <td>2022-12-10</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>61.385709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>TikTok</td>\n",
              "      <td>2022-12-12</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>60.527460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Machine Learning Engineer (NLP)</td>\n",
              "      <td>BLACKBIRD.AI</td>\n",
              "      <td>2022-09-11</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
              "      <td>60.479719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>TikTok</td>\n",
              "      <td>2022-12-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>60.370927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>2022-12-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>59.261380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Data Strategy, Data Scientist – Equity Research</td>\n",
              "      <td>Jefferies</td>\n",
              "      <td>2022-11-22</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-strate...</td>\n",
              "      <td>59.012670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Atlantic Partners Corporation</td>\n",
              "      <td>2022-10-23</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>58.681862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Carrie Rikon &amp; Associates, LLC</td>\n",
              "      <td>2022-11-26</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>58.595426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Scientist, Product</td>\n",
              "      <td>Asana</td>\n",
              "      <td>2022-12-08</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>58.445227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Data Scientist [NYC]</td>\n",
              "      <td>CarbonChain</td>\n",
              "      <td>2022-12-02</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>58.214526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Carrie Rikon &amp; Associates, LLC</td>\n",
              "      <td>2022-11-26</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>58.211078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Data Scientist Full Time</td>\n",
              "      <td>Bardess Group Ltd</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>56.927022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Grammarly</td>\n",
              "      <td>2022-12-02</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>55.874025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Top Prospect Group</td>\n",
              "      <td>2022-12-13</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>55.733844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Data Scientist - Marketing Analytics</td>\n",
              "      <td>Spotify</td>\n",
              "      <td>2022-12-08</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>55.393283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>lululemon Studio</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>55.162251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Revelio Labs</td>\n",
              "      <td>2022-11-26</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>51.273488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Amicus</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>47.970391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Machine Learning Engineer - US Remote</td>\n",
              "      <td>Hugging Face</td>\n",
              "      <td>2022-11-13</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
              "      <td>47.785271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Machine Learning Engineer</td>\n",
              "      <td>Verneek</td>\n",
              "      <td>2022-11-23</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
              "      <td>47.075169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>McKinney</td>\n",
              "      <td>2022-11-26</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>46.838460</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4741674-6f54-4f4e-8b63-4e21d3d91c35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4741674-6f54-4f4e-8b63-4e21d3d91c35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4741674-6f54-4f4e-8b63-4e21d3d91c35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Here are the top 10 recommended jobs based on your resume:')\n",
        "final_info_table.nlargest(10,['Matching_percentage'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "z-zS2n0pgnF6",
        "outputId": "9f7ed7db-b5c5-4c95-d9f8-2f867dac571a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the top 10 recommended jobs based on your resume:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Job_title              Company  \\\n",
              "22                                   Data Scientist           Afficiency   \n",
              "7           Data Scientist (Deep Learning), Peacock              Peacock   \n",
              "14         Data Scientist - Global Decision Science     American Express   \n",
              "0                 Data Scientist, Product Analytics  Peloton Interactive   \n",
              "3                                    Data Scientist              Epsilon   \n",
              "2                                    Data Scientist               TikTok   \n",
              "24                  Machine Learning Engineer (NLP)         BLACKBIRD.AI   \n",
              "10                                   Data Scientist               TikTok   \n",
              "11                                   Data Scientist   The New York Times   \n",
              "20  Data Strategy, Data Scientist – Equity Research            Jefferies   \n",
              "\n",
              "   Job_posted_date                                               Link  \\\n",
              "22      2022-11-09  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "7       2022-12-06  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "14      2022-12-01  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "0       2022-12-14  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "3       2022-12-10  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "2       2022-12-12  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "24      2022-09-11  https://www.linkedin.com/jobs/view/machine-lea...   \n",
              "10      2022-12-03  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "11      2022-12-03  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "20      2022-11-22  https://www.linkedin.com/jobs/view/data-strate...   \n",
              "\n",
              "    Matching_percentage  \n",
              "22            62.934231  \n",
              "7             62.874773  \n",
              "14            62.232565  \n",
              "0             61.883468  \n",
              "3             61.385709  \n",
              "2             60.527460  \n",
              "24            60.479719  \n",
              "10            60.370927  \n",
              "11            59.261380  \n",
              "20            59.012670  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42c7956b-ddc7-4401-a2a3-b64aef60ec93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job_title</th>\n",
              "      <th>Company</th>\n",
              "      <th>Job_posted_date</th>\n",
              "      <th>Link</th>\n",
              "      <th>Matching_percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Afficiency</td>\n",
              "      <td>2022-11-09</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>62.934231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Data Scientist (Deep Learning), Peacock</td>\n",
              "      <td>Peacock</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>62.874773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Data Scientist - Global Decision Science</td>\n",
              "      <td>American Express</td>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>62.232565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Scientist, Product Analytics</td>\n",
              "      <td>Peloton Interactive</td>\n",
              "      <td>2022-12-14</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>61.883468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Epsilon</td>\n",
              "      <td>2022-12-10</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>61.385709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>TikTok</td>\n",
              "      <td>2022-12-12</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>60.527460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Machine Learning Engineer (NLP)</td>\n",
              "      <td>BLACKBIRD.AI</td>\n",
              "      <td>2022-09-11</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
              "      <td>60.479719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>TikTok</td>\n",
              "      <td>2022-12-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>60.370927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>2022-12-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>59.261380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Data Strategy, Data Scientist – Equity Research</td>\n",
              "      <td>Jefferies</td>\n",
              "      <td>2022-11-22</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-strate...</td>\n",
              "      <td>59.012670</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42c7956b-ddc7-4401-a2a3-b64aef60ec93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42c7956b-ddc7-4401-a2a3-b64aef60ec93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42c7956b-ddc7-4401-a2a3-b64aef60ec93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rzq317lvuRCw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}